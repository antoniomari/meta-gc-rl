name:  &job_name antmaze-gradsteps
results_dir: /fast/malbaba/results/offline_finetuning
git_branch: main
git_commit: null
script_path: main.py
pre_script: null
cluster_requirements:
  cpus: 8
  ram: 32G
  gpus: 1
  disk: 64GB
  bid: 25
  forbidden_hostnames: ['g054']
  time: 24:00:00
default_params: default.yaml
grid:
  run_group: *job_name
  eval_interval: 50000
  log_interval: 5000
  save_interval: 50000
  eval_start: 350000
  eval_on_cpu: 0
  eval_episodes: 3
  '[env_name, agent.agent_name, agent.actor_loss, finetune.actor_loss, agent.alpha, agent.actor_p_randomgoal, agent.actor_p_trajgoal]': [
    [antmaze-medium-stitch-v0, gciql, awr, awr, 0.3, 0.5, 0.5],
  ]

  # 624, 732, 992, 1332
  '[agent.actor_hidden_dims, agent.value_hidden_dims, train_steps, eval_start]': [
    [[512, 512, 512], [512, 512, 512], 500000, 350000],
  ]


  agent.high_alpha: 3.0
  agent.low_alpha: 3.0
  #agent.alpha: 0.3

  finetune.lr: 3.e-4
  finetune.ratio: 1.0
  finetune.fix_actor_goal: 1.0
  finetune.filter_by_td: false
  finetune.mc_quantile: 0.2 #0.2
  finetune.mc_slack: 5 #10 # might change this to 5
  finetune.sorb_len: 5 # not important for recursive
  finetune.td_correction_horizon: 20
  finetune.td_quantile: 0.2
  finetune.filter_by_argmax: false
  finetune.filter_by_nstep_td: false
  finetune.max_steps: 15

  '[finetune.num_steps, finetune.filter_by_mc, finetune.filter_by_recursive_mdp, finetune.min_steps, finetune.replan_horizon, finetune.mc_similarity_threshold]': [
    [50, false, true, 10, 100, 1.0],
    [150, false, true, 10, 100, 1.0],
    [200, false, true, 10, 100, 1.0],
    [250, false, true, 10, 100, 1.0],
    [300, false, true, 10, 100, 1.0],
  ]

  seed: [0, 1, 2]

